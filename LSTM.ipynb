{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer as sia \n",
    "df = pd.read_csv('Restaurant_Reviews.csv', delimiter = '\\t', quoting = 3)\n",
    "positivity=[]\n",
    "negativity=[]\n",
    "overall_sentiment=[]\n",
    "\n",
    "sid_obj=sia()\n",
    "\n",
    "for review in df[\"Review\"]:\n",
    "    sentiment_dict = sid_obj.polarity_scores(review)\n",
    "    positivity.append(sentiment_dict['pos'])\n",
    "    negativity.append(sentiment_dict['neg'])\n",
    "    overall_sentiment.append('pos' if sentiment_dict['pos']> sentiment_dict['neg'] else 'neg' if sentiment_dict['pos']<sentiment_dict['neg'] else 'pos')\n",
    "\n",
    "df.insert(2,'Pos',positivity)\n",
    "df.insert(3,'Neg',negativity)\n",
    "df.insert(4,'Senti',overall_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review']= [x.lower() for x in df['Review']]\n",
    "df['Review'] = df['Review'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,row in df.iterrows():\n",
    "    row[0] = row[0].replace('rt',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth',-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Review']= [x.encode('ascii') for x in df['Review']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Neg</th>\n",
       "      <th>Senti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>b'wow loved this place'</td>\n",
       "      <td>1</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.000</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>b'crust is not good'</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.445</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>b'not tasty and the texture was just nasty'</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.340</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>b'stopped by during the late may bank holiday off rick steve recommendation and loved it'</td>\n",
       "      <td>1</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.093</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>b'the selection on the menu was great and so were the prices'</td>\n",
       "      <td>1</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.000</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995</td>\n",
       "      <td>b'i think food should have flavor and texture and both were lacking'</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>996</td>\n",
       "      <td>b'appetite instantly gone'</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>997</td>\n",
       "      <td>b'overall i was not impressed and would not go back'</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.221</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>998</td>\n",
       "      <td>b'the whole experience was underwhelming and i think well just go to ninja sushi next time'</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999</td>\n",
       "      <td>b'then as if i hadnt wasted enough of my life there they poured salt in the wound by drawing out the time it took to bring the check'</td>\n",
       "      <td>0</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.000</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                    Review  \\\n",
       "0    b'wow loved this place'                                                                                                                 \n",
       "1    b'crust is not good'                                                                                                                    \n",
       "2    b'not tasty and the texture was just nasty'                                                                                             \n",
       "3    b'stopped by during the late may bank holiday off rick steve recommendation and loved it'                                               \n",
       "4    b'the selection on the menu was great and so were the prices'                                                                           \n",
       "..                                                             ...                                                                           \n",
       "995  b'i think food should have flavor and texture and both were lacking'                                                                    \n",
       "996  b'appetite instantly gone'                                                                                                              \n",
       "997  b'overall i was not impressed and would not go back'                                                                                    \n",
       "998  b'the whole experience was underwhelming and i think well just go to ninja sushi next time'                                             \n",
       "999  b'then as if i hadnt wasted enough of my life there they poured salt in the wound by drawing out the time it took to bring the check'   \n",
       "\n",
       "     Liked    Pos    Neg Senti  \n",
       "0    1      0.794  0.000  pos   \n",
       "1    0      0.000  0.445  neg   \n",
       "2    0      0.000  0.340  neg   \n",
       "3    1      0.322  0.093  pos   \n",
       "4    1      0.272  0.000  pos   \n",
       "..  ..        ...    ...  ...   \n",
       "995  0      0.000  0.000  pos   \n",
       "996  0      0.000  0.000  pos   \n",
       "997  0      0.000  0.221  neg   \n",
       "998  0      0.000  0.000  pos   \n",
       "999  0      0.089  0.000  pos   \n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\keras_preprocessing\\text.py:178: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(nb_words=2000, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                                   lower=True,split=' ')\n",
    "df = df.astype({\"Review\":str})\n",
    "tokenizer.fit_on_texts(df['Review'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tokenizer.texts_to_sequences(df['Review'].values)\n",
    "X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: The `dropout` argument is no longer support in `Embedding`. You can apply a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.\n",
      "  \n",
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(196, dropout=0.2, recurrent_dropout=0.2)`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 32, 128)           256000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 196)               254800    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 394       \n",
      "=================================================================\n",
      "Total params: 511,194\n",
      "Trainable params: 511,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "batch_size = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(2000, embed_dim,input_length = X.shape[1], dropout = 0.2))\n",
    "model.add(LSTM(lstm_out, dropout_U = 0.2, dropout_W = 0.2))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 32) (800, 2)\n",
      "(200, 32) (200, 2)\n"
     ]
    }
   ],
   "source": [
    "Y = pd.get_dummies(df['Senti']).values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.2, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 2s - loss: 0.0053 - accuracy: 0.9987\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.0109 - accuracy: 0.9962\n",
      "Epoch 3/10\n",
      " - 3s - loss: 0.0069 - accuracy: 0.9987\n",
      "Epoch 4/10\n",
      " - 3s - loss: 0.0137 - accuracy: 0.9962\n",
      "Epoch 5/10\n",
      " - 3s - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      " - 2s - loss: 0.0055 - accuracy: 0.9975\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.0039 - accuracy: 0.9975\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.0050 - accuracy: 0.9975\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.0030 - accuracy: 0.9987\n",
      "Epoch 10/10\n",
      " - 2s - loss: 0.0037 - accuracy: 0.9975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21f5c1d50c8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size = batch_size, nb_epoch = 10, verbose =2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 1.46\n",
      "Validation Accuracy: 0.73\n"
     ]
    }
   ],
   "source": [
    "score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
    "print(\"Score: %.2f\" % (score))\n",
    "print(\"Validation Accuracy: %.2f\" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
